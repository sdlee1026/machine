{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_dataset = load_iris()\n",
    "# 데이터 적재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_lris()가 반환한 객체는 dictonary와 유사한 Bunch 의 객체, 키와 값으로 구성되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris_dataset의 key:\n",
      " dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "print('iris_dataset의 key:\\n', iris_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descp(description) 키에는 데이터셋에 대한 간단한 설명이 들어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, pre\n"
     ]
    }
   ],
   "source": [
    "print(iris_dataset['DESCR'][:193])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타깃의 이름 : ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print('타깃의 이름 :',iris_dataset['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성의 이름 : ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print('특성의 이름 :',iris_dataset['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#실제 데이터는 target과 data 필드에 들어가 있음\n",
    "#data는 꽃잎의 길이와 폭 1,2\n",
    "#꽃받침의 길이와 폭을 3,4\n",
    "#수치 값으로 가지고 있는 Numpy 배열\n",
    "print(type(iris_dataset['data']))\n",
    "iris_dataset['data'].shape\n",
    "# 150개의 꽃(샘플), 각 꽃에서 구한 측정치_속성(특성)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data의 첫 다섯행:\n",
      " [[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]]\n"
     ]
    }
   ],
   "source": [
    "print('data의 첫 다섯행:\\n', iris_dataset['data'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이와 같은 데이터 셋은 품종을 정확하게 분류한 데이터를 가지고 있기 때문에 지도 학습에 속한다.\n",
    "# 즉 분류(Classification)문제에 속함, 출력될 수 있는 꽃들의 품종은 클래스에 속한다\n",
    "# 데이터 포인트 하나(붓꽃 하나)에 대한 기대 출력은 꽃의 품중이 됩니다.\n",
    "# 이런 특정 데이터 포인트에 대한 출력, 즉 품종(answer)을 레이블(label)이라고 합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "타깃의 이름 : ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print('타깃의 이름 :',iris_dataset['target_names'])\n",
    "# 각각 0,1,2 라벨링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 데이터를 통해 들어오는 값에 따라서 꽃의 종류를 분류하는 머신 러닝 모델을 만들겠음\n",
    "# 새 데이터에 적용하기 전에 잘 작동하는지, (만든 모델의 예측을 신뢰할 수 있는지 알아보아야함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용한 데이터를 사용해서 실제 성능을 측정하는 것은 옳지 않음, 세 데이터를 모델에 적용시켜보아야..\n",
    "# 따라서 보편적으로 가지고 있는 데이터를 두 그룹 (train, test)으로 나눠서 사용하는 것이 일반적\n",
    "# scikit-learn은 데이터 셋을 섞어서 나눠주는 train_test_split 함수를 지원, 유용하게 사용할 수 있을 것_ 대게는 75%를 학습, 25%를 테스트로 사용\n",
    "# * train_test_split 함수에서 test_size 매개변수로 테스트 세트의 비율을 지정할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 보편적으로 데이터는 X, 레이블(라벨)은 y로 표기한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_dataset['data'], iris_dataset['target'], random_state=0)\n",
    "# train_test_split 함수로 데이터를 나누기 전에 유사 난수 생성기를 사용해, 데이터 셋을 무작위로 섞어야함\n",
    "# 이 함수를 여러번 실행해도 같은 결과가 나오도록 유사 난수 생성기에 넣을 난수 초기값을 random_state 매개변수로 전달함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split 함수의 반환값은 X_train, X_test, y_train, y_test 이며, 모두 Numpy 배열..\n",
    "# X_train은 전체 데이터의 75% X_test은 25%를 담고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape : (112, 4) y_train shape : (112,)\n",
      "X_test shape : (38, 4) y_test shape : (38,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape : {} y_train shape : {}'.format(X_train.shape, y_train.shape))\n",
    "print('X_test shape : {} y_test shape : {}'.format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0, 2, 0, 2, 0, 1, 1, 1, 2, 1, 1, 1, 1, 0, 1, 1, 0, 0, 2, 1,\n",
       "       0, 0, 2, 0, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 0, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n",
    "# 이와같이 섞여있다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
