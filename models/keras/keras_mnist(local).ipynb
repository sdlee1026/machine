{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_SAVE_FOLDER_PATH = './model/'\n",
    "\n",
    "if not os.path.exists(MODEL_SAVE_FOLDER_PATH):\n",
    "    os.mkdir(MODEL_SAVE_FOLDER_PATH)\n",
    "\n",
    "model_path = MODEL_SAVE_FOLDER_PATH + 'mnist-' + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "# 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어떤 코드인지 내일 알아볼것\n",
    "# ModelCheckpoint 및 EarlyStopping 모듈까지 적용\n",
    "cb_checkpoint = ModelCheckpoint(filepath=model_path, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "cb_early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train), (X_validation, Y_validation) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 103 254 254 255 184  73   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0  85 169 245 253 253 253 253 253 230  97   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0  91 233 253 160  89  95 232 253 253 253 125   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0 187 253 117   7   0   6 136 242 253 251 112   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0 200 253 113   2  76  75 194 253 253 159   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0 177 253 239 228 216 253 253 253 173  10   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0  27 200 253 253 253 253 253 253 102   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   6  14  15 102 253 253 159   5   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0  41 216 253 190  19   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0  30 153 253 248  51   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0  94 253 252 120  17   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0  47 250 252 148   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0  25 182 253 203   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0 206 253 220  50   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   3  92 252 244 106   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0  50 226 241 109   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0  40 235 253 137  24   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0  15 208 253 190  29   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0  30 218 240 146   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   4 160 167  70   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n",
      "  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 \n"
     ]
    }
   ],
   "source": [
    "for x in X_train[33]:\n",
    "    for i in x:\n",
    "        print('{:3} '.format(i), end='')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15956, saving model to ./model/mnist-01-0.1596.hdf5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.15956 to 0.10936, saving model to ./model/mnist-02-0.1094.hdf5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.10936 to 0.08572, saving model to ./model/mnist-03-0.0857.hdf5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08572 to 0.07424, saving model to ./model/mnist-04-0.0742.hdf5\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.07424\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.07424 to 0.06151, saving model to ./model/mnist-06-0.0615.hdf5\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.06151\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.06151 to 0.05770, saving model to ./model/mnist-09-0.0577.hdf5\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.05770\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.05770\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.05770\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.05770\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.05770\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.05770\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.05770\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.05770\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.05770\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.05770\n",
      "10000/10000 [==============================] - 0s 31us/step\n",
      "\n",
      "Accuracy: 0.9822\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 784).astype('float64') / 255\n",
    "# 가로 28, 세로 28 픽셀의 이미지 -> 1*784 1차원 행렬로 변환\n",
    "# 각 픽셀당 가지는 값(0-255), 255나눠서 nomalization\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], 784).astype('float64') / 255\n",
    "\n",
    "Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "Y_validation = np_utils.to_categorical(Y_validation, 10)\n",
    "\n",
    "# 결과값에 대해서는 One-hot-Encoding 적용\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_dim=784, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, validation_data=(X_validation, Y_validation),\n",
    "          epochs=30, batch_size=200, verbose=0,\n",
    "          callbacks=[cb_checkpoint, cb_early_stopping])\n",
    "\n",
    "print('\\nAccuracy: {:.4f}'.format(model.evaluate(X_validation, Y_validation)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
