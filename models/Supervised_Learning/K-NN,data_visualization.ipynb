{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러 모델들에서 모델의 복잡도가 어떤 역할을 하는지 이야기하고 각 알고리즘들이 모델을 어떻게 만드는지 학습해보겠음\n",
    "# 또한, 모델들의 장단점을 파악하고, 모델별로 어떤 데이터가 잘 들어맞을지 살펴 볼 것임\n",
    "# 분류와 회귀 모델을 모두 가지고 있는 알고리즘도 많은데 이런 경우 둘다 살펴 볼 것임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "font size : 10.0\n",
      "font family : ['NanumGothic']\n",
      "python version : 3.7.6 (v3.7.6:43364a7ae0, Dec 18 2019, 14:18:50) \n",
      "[Clang 6.0 (clang-600.0.57)]\n",
      "pandas version : 0.25.3\n",
      "matplotlib version : 3.1.2\n",
      "numpy version : 1.18.1\n",
      "\n",
      "time.struct_time(tm_year=2020, tm_mon=2, tm_mday=6, tm_hour=8, tm_min=1, tm_sec=9, tm_wday=3, tm_yday=37, tm_isdst=0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import collections\n",
    "from IPython.display import display\n",
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import font_manager, rc\n",
    "import pandas as pd\n",
    "import mglearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "font_fname = 'fonts/NanumGothic.ttf'\n",
    "font_name = font_manager.FontProperties(fname=font_fname).get_name()\n",
    "\n",
    "rc('font', family=font_name)\n",
    "# size, family\n",
    "print ('font size : '+str(plt.rcParams['font.size']) )\n",
    "print ('font family : '+str(plt.rcParams['font.family']) )\n",
    "# import default setting\n",
    "print('python version : {0}\\npandas version : {1}\\nmatplotlib version : {2}\\nnumpy version : {3}\\n'\n",
    ".format(sys.version, pd.__version__, mpl.__version__, np.__version__))\n",
    "import time\n",
    "print(time.gmtime())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이진분류(classification)_forge dataset_시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forge 데이터셋은 인위적으로 만든 이진 분류 데이터셋임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape (26, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# dataset setting\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "# 산점도를 그림 discrete_scatter 2차원 산점도 그래프를 위한..\n",
    "mglearn.discrete_scatter(X[:,0], X[:,1], y)\n",
    "# help(mglearn.discrete_scatter)\n",
    "# x1 : nd-array input data, first axis\n",
    "# x2 : nd-array input data, second axis\n",
    "# y : nd-array input data, discrete labels\n",
    "plt.legend(['클래스 0', '클래스1'], loc =4)\n",
    "plt.xlabel('첫번째 특성')\n",
    "plt.ylabel('두번째 특성')\n",
    "print('X.shape',X.shape)\n",
    "# dataset은 데이터26개(포인터)와 2개의 특성을 가짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 회귀(regression)_wave dataset_시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wave dataset : 입력특성 한 종류와 모델링을 위한 타깃변수(출력)을 가짐\n",
    "# x축 : 입력 특성\n",
    "# y축 : 회귀(regression)의 출력(타깃변수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "# n_sample : 입력 특성의 갯수\n",
    "plt.plot(X,y,'o')\n",
    "plt.ylim(-2.8,2.5)\n",
    "# y축 범위 세팅 \n",
    "plt.xlabel('특성')\n",
    "plt.ylabel('타깃')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 유방암 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "# 유방암 데이터셋\n",
    "# 각 종양은 양성종양(benign) 악성종양(malognant)로 나뉨(label화)\n",
    "# 조직 데이터를 기반으로 종양이 악성인지 예측하는 것을 목표로 하겠음\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "print('type : ' + str(type(cancer)))\n",
    "# scikit-learn에 포함된 데이터셋은 실제 데이터와 관련 정보를 가진 Bunch 객체에 저장되어 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bunch객체는 Dictionary와 비슷하지만, 점표기법(EX_.keys())을 사용할 수 있음\n",
    "# ex) bunch['key'] 대신 bunch.key 가능\n",
    "print('cancer.keys():\\n',cancer.keys())\n",
    "print('\\n\\ncancer.data:\\n',cancer.data)\n",
    "print('\\n\\ncancer.data:\\n',cancer['data'])\n",
    "# 동일하게 기능하는 것을 알 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('유방암 데이터의 형태 : ', str(cancer.data.shape) + '\\n569개의 데이터포인트와 30개의 특성을 가지고 있음')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cancer.target_names)\n",
    "# 클래스 분류명\n",
    "print(type(cancer.target))\n",
    "print('0 : 악성, 1 : 양성 \\n'+'[0,1]'+str(np.bincount(cancer.target)))\n",
    "# 212 악성, 357 양성 종양\n",
    "# bincount(~~)\n",
    "#count of zeros is at first_index -> '0'\n",
    "#count of ones is at second_index -> '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cancer.target\n",
    "print(collections.Counter(x))\n",
    "# collections.Counter()사용\n",
    "print(np.count_nonzero(x))\n",
    "# Numpy_count_nonzero 메소드 사용\n",
    "print('클래스(분류)별 샘플 갯수  :\\n',\n",
    "     {n: v for n,v in zip(cancer.target_names, np.bincount(cancer.target))})\n",
    "\n",
    "print('리스트 내부 포문 사용 하지 않을 시')\n",
    "for n,v in zip(cancer.target_names, np.bincount(cancer.target)):\n",
    "    print(n,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보스턴 주택가격 데이터셋(회귀분석)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 데이터셋을 이용, 범죄율, 찰스강 인접도, 고속도로 접근성 등의 정보를 이용해\n",
    "# 1970년대 보스턴 주택 평균 가격을 예측하는 것\n",
    "# 데이터 포인트 506, 특성 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "print('데이터의 형태',boston.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마찬가지로 boston 객체의 DESCR 속성에서 정보 확인 가능\n",
    "# 이 데이터셋에서 13개의 입력 특성뿐만 아니라 특성끼리 곱하여(상호작용) 의도적으로 확장할 것\n",
    "# ex) 범죄율과 고속도로의 접근성의 개별 특성은 물론, 범죄율과 고속도로의 접근성의 곱의 벨류도 특성으로 생각한다는 것\n",
    "# 이처럼 특성을 유도해내는 것을 특성 공학(feature engineering)이라함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "# 13개의 특성, 중복을 허용한 특성의 곱에 원래 특성을 더해 총 104개의 특성을 가지게 됨\n",
    "# 첫번째 특성으로 13개의 교차항이 만들어지고, 두번째 특성에서 첫번째 특성을 제외한 12개의 교차항이 ..(조합)\n",
    "# 중복을 포함한 조합을 만듬 -> scikit-learn의 PolynomialFeatures 함수 사용\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조합(이항계수)_중복을 포함한경우의\n",
    "# (13+12+11 ... +1 = 91) 91+13 < 중복을 포함해야 하므로\n",
    "# 이항계수(Binomial Coefficient)는 조합론에서 등장하는 개념으로 주어진 크기 집합에서 원하는 개수만큼 순서없이 뽑는 조합의 가짓수를 일컫는다. \n",
    "# 2를 상징하는 ‘이항’이라는 말이 붙은 이유는 하나의 아이템에 대해서는 ‘뽑거나, 안 뽑거나’ 두 가지의 선택만이 있기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('이항계수 공식')\n",
    "Image(\"./img/이항계수 공식.png\") # code안에서 나오게 할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('이항계수 성질')\n",
    "Image(\"./img/이항계수 성질.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 간단하 머신러닝 알고리즘\n",
    "# 훈련 데이터 셋을 저장하는 것이 모델을 만드는 과정의 전부\n",
    "# 복습) 새로운 데이터 포인트에 대한 예측을 할땐, 알고리즘이 훈련 데이터셋에서 가장 가까운 데이터 포인터, 즉 '최근접이웃'을 찾음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forge 데이터셋에 대한 1-KNN 모델 예측 시각화\n",
    "mglearn.plots.plot_knn_classification(n_neighbors=1)\n",
    "# mglearn 라이브러리->plots들..->plot_knn분류\n",
    "# 추가한 데이터 포인터 3개 별모양\n",
    "# 그리고 추가한 데이터 포인터로 부터 가장 가까운 훈련 데이터 포인트를 연결함\n",
    "# 1-KNN 알고리즘의 예측은 연결된 데이터 포인트에 연관되어 집니다(연결선)\n",
    "# 1-KNN predict: blue, orange, blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forge 데이터셋에 대한 5-KNN 모델 예측 시각화\n",
    "mglearn.plots.plot_knn_classification(n_neighbors=5)\n",
    "# 연결된 데이터 포인트(이웃)의 색과 수에 따라서 예측 결과값은 달라짐\n",
    "# 5-KNN predict : orange, orange, blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위의 데이터 셋은 이진 분류 문제지만, 클래스가 다수인 데이터셋에도 KNN을 적용할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN 적용, KNeighborsClassifier 분석(시각화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn을 이용 k-NN 적용법을 살펴보겠음\n",
    "# 모델의 일반화 성능을 평가하기 위해서 훈련세트, 테스트 세트 세팅\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0)\n",
    "# 이 함수를 여러번 실행해도 같은 결과가 나오도록 유사 난수 생성기에 넣을 난수 초기값을 random_state 매개변수로 0 전달\n",
    "\n",
    "# KNeighborsClassifier import 객체 생성\n",
    "from sklearn.neighbors import KNeighborsClassifier # sklenarn의 KNN(이웃..)\n",
    "\n",
    "clf_test = KNeighborsClassifier(n_neighbors=3) # Classifier 매개변수(이웃3), 객체 생성 메소드\n",
    "clf_test.fit(X_train, y_train) # 학습\n",
    "\n",
    "print('test data 예측 : '+ str(clf_test.predict(X_test)))\n",
    "print('train data score : {:.2f}'.format(clf_test.score(X_train, y_train)))\n",
    "print('test data score : {:.2f}'.format(clf_test.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차원 데이터 셋이므로 모든 테스트 포인트의 예측을 xy 평면에 그릴 수 있음\n",
    "# 각 클래스 분류에 따라 다른 색을 칠하여 클래스분류의 경계 (결정 경계_decision boundary)를 볼 수있음\n",
    "# n_neighbor 의 매개변수 (즉, 이웃의 수)가 1,3,9 개 일때의 차이를 시각해서 보여보자\n",
    "fig, axes = plt.subplots(1,3, figsize = (10,3))\n",
    "# plt.subplots() 함수에 대한 정리(공부)machine/libs_study/matplotlib_pyplot(as_plt)/plt_subplots().ipynb 참조\n",
    "\n",
    "for n_neighbors, ax in zip([1,3,9], axes):\n",
    "    # fit 메소드는 자기자신(self object)을 다시 리턴하기 때문(갱신)\n",
    "    # 객체 생성 메소드와 fit 메소드 한줄에 작성 가능\n",
    "    clf_forge = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X,y)\n",
    "    \n",
    "    # 2차원 plots 메소드, default 매개변수 \n",
    "    # plot_2d_separator(classifier, X, fill=False, ax=None, eps=None, alpha=1,\n",
    "    # cm=<matplotlib.colors.ListedColormap object at 0x1220c8b10>, linewidth=None, threshold=None, linestyle='solid')\n",
    "    mglearn.plots.plot_2d_separator(clf_forge, X, fill=True, eps = 0.5, ax=ax, alpha=0.4)\n",
    "    \n",
    "    # 산점도\n",
    "    mglearn.discrete_scatter(X[:,0],X[:,1],y, ax=ax)\n",
    "    \n",
    "    # axes(array) 안의 ax들 setting _ (ax == matplotlib.axes._subplots.AxesSubplot object)\n",
    "    ax.set_title('{}이웃'.format(n_neighbors))\n",
    "    ax.set_xlabel('특성 0')\n",
    "    ax.set_ylabel('특성 1')\n",
    "    ax.legend() # 라벨링 플레이싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1이웃의 경우 결정 경계가 훈련데이터를 주로 따라가고\n",
    "# 이웃이 늘어날 수록 경계는 부드러워 짐을 알 수 있음\n",
    "# 부드러운 경계는 더 단순한 모델을 의미함, 다시 말해 이웃을 적게 사용하면 모델의 복잡도는 높아지고\n",
    "# 많이 사용하면 모델의 복잡도는 낮아짐\n",
    "# 극단적으로 훈련 데이터 포인터의 전체 갯수를 이웃으로 지정하게 되면 모든 테스트 포인트가 같은 이웃을 가지게됨\n",
    "# 그러므로 테스트 포인트에 대한 예측은 모두 같은 값이 될것임\n",
    "# 즉 훈련 세트에서 가장 많은 데이터 포인트를 가진 클래스가 예측값이 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 복잡도와 일반화 사이의 관계를 입증할 수 있는지 살펴보겠음\n",
    "# 유방암 데이터셋 사용, 이웃의 수를 바꿔가며 훈련 세트와 테스트 세트의 성능을 평가\n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target, stratify=cancer.target, random_state=66)\n",
    "# 참조 machine/libs_study/sklearn.model_selection_study/train_test_split_study.ipynb\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# 1 ~ 10 까지 이웃갯수 사용\n",
    "neighbors_setting = range(1,11)\n",
    "for n_neighbors in neighbors_setting:\n",
    "    clf_cancer = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X_train,y_train) # 모델 생성, 저장\n",
    "    training_accuracy.append(clf_cancer.score(X_train,y_train)) #훈련 세트 스코어 저장\n",
    "    test_accuracy.append(clf_cancer.score(X_test,y_test)) # 테스트 세트(일반화) 스코어 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(neighbors_setting, training_accuracy, label='훈련 정확도')\n",
    "plt.plot(neighbors_setting, test_accuracy, label='테스트 정확도')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이웃수(x축)에 따른 훈련, 테스트 정확도(y축)을 보여주는 그래프\n",
    "# 실제로 이렇게 매끄러운 그래프는 나오지 않지만\n",
    "# 여기서도 과적합 과소적합의 특징을 볼 수있음\n",
    "# 이웃의 수가 적어질 수록 모델이 복잡히지므로, 그래프는 수평으로 뒤집힌 형태이며\n",
    "# 이웃의 수가 하나일때 훈련 데이터에 과적합, 이웃의 수가 늘어날 수록 모델은 단순해지며\n",
    "# 훈련 데이터의 정확도는 줄어듬, 하지만 테스트 정확도의 그래프도 참조해야함\n",
    "# 반대로 이웃을 10개 사용하였을 경우 모델이 너무 단순해져서 정확도가 낮아짐을 알 수가 있음\n",
    "# 가장 최적점을 찾아보면 6개 정도의 이웃을 사용한 KNN이 적합하다고 이 시각화에서 볼 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN 알고리즘은 회귀 분석(Regression)에도 쓰임\n",
    "# wave dataset 사용\n",
    "# 3개의 test data, 초록 star 모양 표시\n",
    "# 이웃이 하나일때는 그냥 가장 가까운 이웃의 타깃값으로 예측..(진한별)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=1)\n",
    "# feature 값을 입력으로 target 값을 예측한 그래프를 볼 수 있다.. 회귀 문제기 때문에 선형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mglearn.plots.plot_knn_regression(n_neighbors=3)\n",
    "# 여러개의 최근접 이웃을 사용하면 이웃의 평균*이 예측이 됨\n",
    "# * KNeighborsRegressor 의 가중치 매개변수가 uniform_default 일때는 np.mean 함수로 단순 평균 계산\n",
    "# * 가중치 매개변수가 distance 일때는 거리를 고려한 가중치 평균(average)를 계산함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn에서 회귀를 위한 KNN 알고리즘은 KNeighborsRegressor 에 구현되어 있음\n",
    "# 사용법은 KNeighborsClassifier 와 유사함\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 0) # 고정 split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y) # 유동 split << 결정계수의 값(score) 편차 심하게 나옴\n",
    "reg_wave = KNeighborsRegressor(n_neighbors=3).fit(X_train, y_train)\n",
    "\n",
    "print('test set pridict:\\n', np.round_(reg_wave.predict(X_test), 3))\n",
    "# 테스트 세트 예측 출력\n",
    "\n",
    "print('test set R^2 : ')\n",
    "# score 메서드를 사용해 모델 평가 가능, score 메서드는 회귀 일때 R^2(제곱) 값을 반환함\n",
    "# R^2(결정 계수), 회귀 모델에서 예측의 적합도를 측정한 것\n",
    "# 보통 0-1 사아의 값을 가짐. 1은 predict가 완벽한 경우이고\n",
    "# 0은 훈련세트의 출력 값인 y_train 의 평균으로만 예측하는 경우에 나타남\n",
    "    ## y_train 의 평균 값을 예측으로 사용하면, R^2 공식에서 타깃값의 평균과 모델의 예측값이 같게되고\n",
    "    ## 분자와 분모 값이 같아져 최종 계산값은 0이 되기 때문\n",
    "        ### 결정 계수 향후 서술\n",
    "# R^2(결정 계수)는 음수가 나올 수도 있는데, 이는 예측과 타깃이 상반된 경향을 가지는 경우임\n",
    "print('{:.2f}'.format(reg_wave.score(X_test,y_test)))\n",
    "# 0.83의 스코어의 경우 대략 맞아들어간 정도라 생각"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNeighborsRegressor 분석\n",
    "# 1차원 데이터셋(wave) 에 가능한 모든 특성 값을 만들어 예측해 볼 수 있음\n",
    "# 이웃의 수에 따른 그래프를 3개 만들어보겠음\n",
    "fig, axes = plt.subplots(1,3, figsize = (15,4))\n",
    "line = np.linspace(-3, 3, 1000).reshape(-1,1)\n",
    "# -3과 3 사이에 1000개의 데이터 포인터를 만듬\n",
    "# 파이썬 NumPy 에서 배열의 차원(Dimension)을 재구조화, 변경하고자 할 때 reshape() 메소드를 사용\n",
    "# 가령, 3개의 행과 4개의 열로 구성된 2차원의 배열로 재설정하고 싶으면 reshape(3, 4) 처럼 \n",
    "# reshape()의 매개변수로 변경하고자 하는 배열의 행과 열의 차원을 정수로 입력해주면됨\n",
    "# reshape()의 매개변수중 '-1'이 의미하는 바는, 변경된 배열의 '-1' 위치의 차원은 \"원래 배열의 길이와 남은 차원으로 부터 추정\"이 된다는 뜻\n",
    "\n",
    "for n_neighbors, ax in zip([1,3,9], axes):\n",
    "    # 이웃 1,3,9개\n",
    "    reg_wave = KNeighborsRegressor(n_neighbors=n_neighbors).fit(X_train,y_train)\n",
    "    # axes(array) 안의 ax들 setting _ (ax == matplotlib.axes._subplots.AxesSubplot object)\n",
    "    ax.plot(line, reg_wave.predict(line)) # ax 그래프에 line(-3, 3 데이터 1000개) 예측값\n",
    "    ax.plot(X_train, y_train, '^', c = mglearn.cm2(0), markersize = 8) # train data, 삼각형 모양\n",
    "    ax.plot(X_test, y_test,'v', c = mglearn.cm2(1), markersize = 8) # test data , 역삼각형 \n",
    "    # c='~~~' => 표기 도형 색상, marker size => 표기 도형 크기\n",
    "    ax.set_xlabel('특성')\n",
    "    ax.set_ylabel('타깃')\n",
    "    ax.legend(['모델 예측', '훈련 데이터/타깃', '테스트 데이터/타깃'], loc='best') # 라벨링 플레이싱 loc='best' 개꿀팁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 회귀의 경우 이웃을 하나 사용하게 되면, 훈련세트의 각 데이터 포인터에 예측이 과적합을 이루게됨 (불안정한예측)\n",
    "# 이웃을 많이 사용하면, 훈련 데이터에는 잘 맞지 않아도 안정적인 데이터를 얻을 수 있음을 관찰할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN의 중요 매개변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일반적으로 KNN 분류기에 중요한 매개변수는 두개임\n",
    "# 1. 데이터 포인터 사이의 거리를 재는 방법\n",
    "    # Classifier, Regressor 의 객체를 생성할 때 metric 매개변수를 사용, 거리 측정 방식을 변경 가능\n",
    "    # metric의 Default는 민코프스키 거리를 의미하는 'minkowski'이며\n",
    "    # 거듭제곱의 크기를 정하는 매개변수인 p가 기본값 2일 때, 유클라디안 거리와 같음\n",
    "    # 기본적으로 여러 환경에서 잘 작동하는 유클리디안 거리 방식을 사용함\n",
    "# 2. 이웃의 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN의 장단점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 장점\n",
    "# 매우 이해하기 쉬운 모델임\n",
    "# 많이 조정하지 않아도 자주 좋은 성능을 보여주긴 함\n",
    "# 복잡한 알고리즘을 적용해보기 전에 시도해볼 수 있는(간단하게) 시작점이 될 수 있음_baseline\n",
    "\n",
    "# 단점\n",
    "# 보통 최근접 이웃 모델은 매우 빠르게 만들 수 있지만, 훈련 세트가 크면(특성의 수 or 샘플의 수) 예측의 속도가 느려짐 \n",
    "# 또한 KNN의 경우, 데이터의 전처리 과정이 아주 중요함\n",
    "# (수백 개 이상의) 많은 특성을 가진 데이터 셋에는 잘 동작하지 않음\n",
    "# 특성 값이 대부분이 0인 (희소벡터, 희소특성..) 데이터셋과는 잘 작동하지 않음\n",
    "\n",
    "# 총평 : 이해하기 쉽고 빠르게 제작이 가능하지만, 예측이 느리고 많은 특성을 처리하는 능력이 부족해 현업에서 잘 사용하지 않음\n",
    "# 이러한 단점을 선형 모델에서 극복해보도록 해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
