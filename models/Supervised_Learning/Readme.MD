# 지도학습

지도 학습은 입력과 출력 샘플 데이터가 존재, 주어진 입력으로부터 출력을 예측하고자 할 떄 사용함

입력/출력 데이터셋 (훈련 세트)로부터 머신 러닝 모델을 만든 후, 이전에 본 적 없는 새로운 데이터에 대한 정확한 출력을 예측하기 위함이 목표

-------------------------------------------------------

## 분류(Classification)

미리 정의된, 가능성 있는 여러 클래스 레이블(class Lable) 중 하나를 예측하는 것
  
    - 이진 분류(Binary classification), 질문의 답이 'True or False (0 or 1)' 와 같은..
    - 다중 분류(Multiclass classification), 셋 이상의 클래스 레이블로 분류되는 분류

## 회귀(Regresssion)

연속적인 숫지-프로그래밍용어(부동소수점수)_수학용어(실수)를 예측하는 것  
출력 값의 연속성이 있는지 생각해봤을 때, 회귀와 분류 문제를 쉽게 구분 할 수 있음

    - 특정 사람의 교육 수준, 나이, 주거지 등의 정보를 가지고 연봉을 예측한다거나
    - 옥수수 농장의 전년도 수확량, 날씨, 고용 인원수를 토대로 올해 수확량을 예측한다거나
    - 연봉이 40000불에서 40001불로 바뀌었거나, 옥수수 수확량이 200톤에서 198톤이 되는 경우라도 
    
전체적인 의미는 크게 바뀌지 않는다는 점을 생각하라 

사람의 성별 분류가 남자(1), 여자(0) 1의 크기로 결과가 완전히 바뀌는 경우에 비해서

-------------------------------------------------------

## 일반화

지도 학습의 경우에선 훈련 데이터로 학습한 모델이 새로운 데이터에 대해서도 정확히 예측할 것이라 기대함

모델이 처음보는 데이터에 대해서 정확하게 예측할 수 있다면, 이를 훈련 세트에서 테스트 세트로

**일반화(Generalization)** 되었다고 함

## 과적합(Overfitting)

너무 상세하고 너무 적은 데이터에 의존하고 있는 모델은 과적합(Overfitting) 을 겪게 될 수 있음

모델이 훈련 세트의 각 sample에 너무 가깝게 맞춰져서 새로운 데이터에 일반화되기 어려울 떄 일어남

    
    결론적으로 훈련데이터에서 100% 정확도를 달성하는 것은 생각보다 중요하지 않을 수 있음
    
    만약 데이터 셋에서 가진 모든 정보를 모두 사용해서 필요없이 너무 복잡한 모델을 만든다면..
    
## 과소적합(Underfitting)

과적합과 반대로, 정보에 비해 모델이 너무 간단하면

잡아내야 하는 데이터의 면면과 다양성을 잡아내지 못하는 경우가 생긴다, 또한 훈련 세트에 대해서도 잘 맞지 않을 것이다

이처럼 너무 간단한 모델이 선택되는 것을 
**과소적합(Underfitting)**
이라 한다

-------------------------------------------------------

#### 모델을 복잡하게 할수록 훈련 데이터에 대해서는 더 정확히 예측 할 수 있음
#### 그러나, 너무 복잡해지면 훈련 세트에 각 데이터의 포인트에 너무 민갑해져
#### 새로운 데이터에 잘 일반화 되지 못함
#### 우리는 일반화 성능이 최대가 되는 최적점에 있는 모델을 설계해야 함
--------------------------------------------------------

## 모델의 복잡도와 데이터셋 크기의 관계

모델의 복잡도는 훈련 데이터셋에 담긴 입력 데이터의 다양성과 관련성이 깊음

데이터셋에 다양한 데이터 포인트(Data_feature)가 많을 수록 과적합 없이 더 복잡한 모델을 만들 수 있음

그러나 같은 데이터 포인트를 중복하거나, 매우 비슷한 데이터를 모으는 것은 도움이 되지 않음

데이터를 더 많이 수집하고 **전처리** 하는 과정을 거친다면 지도 학습 문제에서 놀라운 결과를 얻을 수 있을 것임
